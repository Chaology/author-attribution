{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who Wrote \"The Fatal Conceit\"? From A Simple Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I analyzed Hayek and his editor William Warren Bartley's writing style (commonly used word using the bag of words) to validate who is more likely be the author of \"The Fatal Conceit\". \n",
    "\n",
    "> There is a scholarly debate on how much influence William Warren Bartley had had on the work \"The Fatal Conceit\" of Nobel Prize Laureates F.A. Hayek. Officially, Bartley was the editor who prepared the book for publication once Hayek fell ill in 1985. However, the inclusion of material from Bartley's philosophical point of view and citations that other people provided to Bartley have led to questions about how much of the book was written by Hayek and whether Hayek knew about the added material. Bruce Caldwell thinks the evidence \"clearly points towards a conclusion that the book was a product more of [Bartley's] pen than of Hayek's. ... Bartley may have written the book\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "import random\n",
    "from nltk.corpus import names\n",
    "from itertools import izip_longest\n",
    "import pickle\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## I selected 6 books of Hayek and 9 books of his author with the similar topic and similar length. The aim is to compare the writing style and common used word of both, so I did not lemmatize the word nor elimiate traditional stop words.\n",
    "\n",
    "\n",
    "## I selected a few stop words to elimiate some words which may cause problems due to overfitting and bug format.(eg., individualism, order appear at every page in one of Hayek's book)\n",
    "stop_words = ['individualism','economic','economics','order','hayek','bartley','popper',\"''\",\"``\"]\n",
    "\n",
    "def grouper(n, iterable, fillvalue=None):\n",
    "    args = [iter(iterable)] * n\n",
    "    return izip_longest(fillvalue=fillvalue, *args)\n",
    "\n",
    "def get_words(f):\n",
    "    text = open(f,'r').read()\n",
    "    words = nltk.word_tokenize(text.decode('utf8'))\n",
    "    useful_words = []\n",
    "    for word in words:\n",
    "        if not word in string.punctuation and not word in stop_words and not (any(i.isdigit() for i in word)) and '.' not in word and '-' not in word:\n",
    "            useful_words.append(word.lower())\n",
    "    unique_words = set(useful_words)\n",
    "    return unique_words\n",
    "\n",
    "\n",
    "word_corpus = set()\n",
    "\n",
    "word_corpus_hayek = set()\n",
    "for i in range(4):\n",
    "    word_corpus_hayek = word_corpus_hayek.union(get_words('books/hayek/book{}.txt'.format(i)))\n",
    "\n",
    "word_corpus_editor = set()\n",
    "editor_files = glob.glob('books/editor/*.txt')\n",
    "for f in editor_files:\n",
    "    word_corpus_editor = word_corpus_editor.union(get_words(f))\n",
    "\n",
    "word_corpus = word_corpus_hayek.union(word_corpus_editor)\n",
    "word_corpus = list(word_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Featureset (Note: this may take a quite long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split each book into pieces of text of length 500. Each one as an observation.\n",
    "\n",
    "n = 500\n",
    "\n",
    "def create_featureset(book, author):\n",
    "    featureset = []\n",
    "    with open(book,'r') as f:\n",
    "        for _, chapter in enumerate(grouper(n, f, fillvalue = ''),1):\n",
    "            current_words = []\n",
    "            for sector in chapter:\n",
    "                sector = sector.decode(\"utf8\")\n",
    "                words_list = nltk.word_tokenize(sector)\n",
    "                for word in words_list:\n",
    "                    if not word in string.punctuation and not word in stop_words and not (any(i.isdigit() for i in word)) and '.' not in word and '-' not in word:\n",
    "                        current_words.append(word)\n",
    "                        \n",
    "            feature = np.zeros(len(word_corpus))\n",
    "            for word in current_words:\n",
    "                if word in word_corpus:\n",
    "                    index_value = word_corpus.index(word)\n",
    "                    feature[index_value] += 1\n",
    "                    \n",
    "            featureset.append([feature, author])\n",
    "    return featureset\n",
    "\n",
    "\n",
    "# Label the observation as 1 if the author is Hayek, if the author is his editor, label it as 0.\n",
    "\n",
    "featureset = []\n",
    "\n",
    "for i in range(4):\n",
    "    featureset += create_featureset('books/hayek/book{}.txt'.format(i),1)\n",
    "\n",
    "for f in editor_files:\n",
    "    featureset += create_featureset(f,0)\n",
    "\n",
    "random.shuffle(featureset)\n",
    "\n",
    "X = np.array([featureset[i][0] for i in range(len(featureset))])\n",
    "y = np.array([featureset[i][1] for i in range(len(featureset))])\n",
    "\n",
    "## I got 182 oberservations and over 30000 unique word as features. (X.shape (182, 33239))\n",
    "\n",
    "## Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## I chosed an ensemble machine learning algorithm XGBC to train a model and validate the result. The result looks good in the original set, but does not work very well at validation sets (I tried to validate it on other books of Hayek, but the result is not very clear.\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Good result both on test set and cross validation. \n",
    "\n",
    "np.mean(y_pred == y_test)\n",
    "### result: 0.97297297297297303\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator= clf, X = X, y=y, cv = 10)\n",
    "print accuracies.mean()\n",
    "print accuracies.std()\n",
    "\n",
    "### result:0.983625730994, 0.0250235004624"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on \"The Fatal Conceit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## I applied the XGBC model to the book \"The Fatal Conceit\". The result indicates that it is not Hayek (only 4 out of 15 pieces of the book were predicted to be Hayek's writing), rather than his editor wrote this book.\n",
    "\n",
    "feature_test = create_featureset('books/fatal-conceit.txt',1)\n",
    "save_f = open('featureset_fatal.pickle','wb')\n",
    "pickle.dump(feature_test, save_f)\n",
    "save_f.close()\n",
    "\n",
    "X_val = np.array([feature_test[i][0] for i in range(len(feature_test))])\n",
    "y_val = np.ones(len(feature_test))\n",
    "\n",
    "y_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred\n",
    "### result: array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0]\n",
    "\n",
    "np.mean(y_pred == y_val)\n",
    "### result: 0.26666666666666666\n",
    "\n",
    "clf.predict_proba(X_val)\n",
    "# result:\n",
    "# array([[ 0.90069646,  0.09930352],\n",
    "#        [ 0.80879188,  0.19120814],\n",
    "#        [ 0.96110272,  0.03889726],\n",
    "#        [ 0.61629498,  0.38370502],\n",
    "#        [ 0.92610949,  0.07389053],\n",
    "#        [ 0.93491316,  0.06508683],\n",
    "#        [ 0.82616472,  0.17383531],\n",
    "#        [ 0.94665325,  0.05334673],\n",
    "#        [ 0.01235527,  0.98764473],\n",
    "#        [ 0.00783384,  0.99216616],\n",
    "#        [ 0.95124978,  0.04875023],\n",
    "#        [ 0.97885853,  0.02114148],\n",
    "#        [ 0.0117451 ,  0.9882549 ],\n",
    "#        [ 0.01979834,  0.98020166],\n",
    "#        [ 0.93806189,  0.06193811]], dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when I tried to validate the model to other books which were certainly written by Hayek. The result is not good. The book I chose are The Intellectuals and Socialism and The Counter-Revolution of Science. The result is correct on The Intellectuals and Socialism but poorly on The Counter-Revolution of Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation on Intellectual and Socialism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_test_1 = create_featureset('books/intellectual.txt',1)\n",
    "\n",
    "X_val_1 = np.array([feature_test_1[i][0] for i in range(len(feature_test_1))])\n",
    "y_val_1 = np.ones(len(feature_test_1))\n",
    "\n",
    "y_pred_1 = clf.predict(X_val_1); y_pred_1\n",
    "### result: array([1, 1])\n",
    "\n",
    "clf.predict_proba(X_val_1)\n",
    "# result:\n",
    "# array([[ 0.0049696 ,  0.9950304 ],\n",
    "#        [ 0.01759064,  0.98240936]], dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation on Counter Revolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_test_2 = create_featureset('books/counter.txt',1)\n",
    "\n",
    "X_val_2 = np.array([feature_test_2[i][0] for i in range(len(feature_test_2))]) \n",
    "y_val_2 = np.ones(len(feature_test_2))\n",
    "y_pred_2 = clf.predict(X_val_2); \n",
    "\n",
    "y_pred_2\n",
    "# result:\n",
    "# array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1])\n",
    "\n",
    "np.mean(y_pred_2 == y_val_2) \n",
    "# result: 0.660377358490566 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different algorithm?\n",
    "So I tried other ml algorithm, SVC, Decision Tree and Multinomial Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_svc = SVC()\n",
    "clf_svc.fit(X_train, y_train)\n",
    "\n",
    "clf_svc.predict(X_val)\n",
    "array([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
    "\n",
    "## Also predicts that the editor is more likely be the author. But the result is still not coherent on The Counter-Revolution of Science.\n",
    "\n",
    "accuracies = cross_val_score(estimator= clf_svc, X = X, y=y, cv = 10)\n",
    "print accuracies.mean()\n",
    "print accuracies.std()\n",
    "# 0.951169590643\n",
    "# 0.056804219319\n",
    "\n",
    "clf_svc.predict(X_val_1)\n",
    "# array([1, 1])\n",
    "\n",
    "clf_svc.predict(X_val_2) \n",
    "# array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tree= DecisionTreeClassifier(criterion='entropy')\n",
    "clf_tree.fit(X_train,y_train)\n",
    "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "\n",
    "accuracies = cross_val_score(estimator= clf_tree, X = X, y=y, cv = 10)\n",
    "print accuracies.mean()\n",
    "print accuracies.std()\n",
    "# 0.972807017544\n",
    "# 0.035979172754\n",
    "\n",
    "clf_svc.predict(X_val)\n",
    "# array([1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
    "\n",
    "## Also predicts that the editor is more likely be the author. But the result is not coherent on The Counter-Revolution of Science.\n",
    "\n",
    "clf_svc.predict(X_val_1)\n",
    "# array([1, 1])\n",
    "\n",
    "clf_svc.predict(X_val_2)\n",
    "# array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
    "#        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_Multi = MultinomialNB()\n",
    "clf_Multi.fit(X_train, y_train)\n",
    "clf_Multi.predict(X_val)\n",
    "array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "## The Multinomial Bayes algorithm predicts that Hayek is very likely to be the author and the result is coherent on validation book.\n",
    "\n",
    "accuracies = cross_val_score(estimator= clf_Multi, X = X, y=y, cv = 10)\n",
    "print accuracies.mean()\n",
    "print accuracies.std()\n",
    "# 0.994736842105\n",
    "# 0.0157894736842\n",
    "\n",
    "clf_Multi.predict(X_val_1)\n",
    "# array([1, 1])\n",
    "\n",
    "clf_Multi.predict(X_val_2)\n",
    "# array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 1, 1, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multinomial Bayes algorithm predicts that Hayek is very likely to be the author and the result is coherent on validation book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Conclusion: The best-validated algorithm indicates that Hayek is more likely be the author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this result is not very robust. The algorithm should be improved in many ways. \n",
    "\n",
    "1. Bag of Word method is not enough to construct the whole feature set, word order, punctuations and other features and better algorithm should be considered. \n",
    "\n",
    "2. The format of text file is not completely clean, some formats are bugging. \n",
    "\n",
    "3. The available text for Hayeks' editor is proportional low and his subject is more focus on philosophy and religion, although I tried to match the similarity of the text from both author. The text of editor is generally more similar to the test feature from \"The Fatal Conceit\".  \n",
    "\n",
    "4. More validation sets should be tested. \n",
    "\n",
    "5. Since W.W. Bartley indeed is the editor of this book, so he at least had some influence over the writing style of this book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
